# å¸¸é‡å®šä¹‰
import pickle
import csv
import datetime
import http.client
import json
import os
import requests

# with open("../api_key.pkl", "wb") as f:
#    pickle.dump(("",""),f) å±é™©

with open("../api_key.pkl", "rb") as f:
    API_KEY = pickle.load(f)

# print(API_KEY)
# print(APIFOX_TOKEN)

MODEL_ID = "ali/qwen3-max"
WEBHOOK_URL = "https://open.feishu.cn/open-apis/bot/v2/hook/d97235b5-9539-4cd6-965d-c0726a81a5eb"

CONNECTION = http.client.HTTPSConnection("router.shengsuanyun.com")
HEADERS = {
    'HTTP-Referer': 'https://www.postman.com',
    'X-Title': 'Postman',
    'Authorization': API_KEY,
    'Content-Type': 'application/json'
}

KNOWLEDGE_BASE = {
    "è®¡è´¹": "æŒ‰é‡ä»˜è´¹æ¯åƒæ¬¡ 0.1 å…ƒï¼ŒåŒ…æœˆ 299 å…ƒä¸é™é‡ã€‚",
    "ä»·æ ¼": "æŒ‰é‡ä»˜è´¹æ¯åƒæ¬¡ 0.1 å…ƒï¼ŒåŒ…æœˆ 299 å…ƒä¸é™é‡ã€‚",
    "è´¹ç”¨": "æŒ‰é‡ä»˜è´¹æ¯åƒæ¬¡ 0.1 å…ƒï¼ŒåŒ…æœˆ 299 å…ƒä¸é™é‡ã€‚",
    "åŠŸèƒ½": "å¹³å°æ”¯æŒæ–‡æœ¬ç”Ÿæˆã€å›¾åƒè¯†åˆ«ã€è¯­éŸ³è½¬æ¢ç­‰å¤šç§AIèƒ½åŠ›ã€‚",
    "API": "æä¾› RESTful æ¥å£ï¼Œæ”¯æŒå¤šè¯­è¨€ SDKã€‚",
    "æ–‡æ¡£": "å®˜æ–¹æ–‡æ¡£ä¸­å¿ƒï¼šhttps://docs.example.com",
}


def log(s: str) -> None:
    """
    æŠŠä¸€æ¡æ—¥å¿—è¿½åŠ åˆ° log.csvã€‚
    """
    # æ„é€ ä¸€è¡Œ
    now = datetime.datetime.now()
    row = [f"{now.year % 100}{now.month:02}{now.day:02} {now.hour:02}{now.minute:02}{now.second:02}.{now.microsecond / 1000:03.0f}", s]

    # ä»¥è¿½åŠ æ¨¡å¼æ‰“å¼€ï¼Œnewline='' é˜²æ­¢ Windows å¤šç©ºè¡Œ
    with open('log.csv', 'a', encoding='utf-8', newline='') as f:
        writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)
        # å¦‚æœæ–‡ä»¶åˆšåˆ›å»ºï¼Œå¯å†™è¡¨å¤´
        if f.tell() == 0:
            writer.writerow(['timestamp', 'message'])
        writer.writerow(row)


# æ¨¡å‹å·¥å…·
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "é£ä¹¦å‘Šè­¦",
            "description": "é€šè¿‡ Webhook å‘æŒ‡å®šé£ä¹¦è´¦å·/ç¾¤å‘é€å¯Œæ–‡æœ¬å¡ç‰‡ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "æŠ¥é”™æ—¶é—´": {
                        "type": "string",
                        "description": "æŠ¥é”™æ—¶é—´",
                    },
                    "é”™è¯¯ä»£ç ": {
                        "type": "string",
                        "description": "é”™è¯¯ä»£ç ",
                    },
                    "å½“å‰å»¶è¿Ÿ": {
                        "type": "string",
                        "description": "å½“å‰å»¶è¿Ÿ",
                    },

                },
                "required": ["æŠ¥é”™æ—¶é—´", "é”™è¯¯ä»£ç ", "å½“å‰å»¶è¿Ÿ"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "Apifox æ–‡æ¡£åŒæ­¥",
            "description": "è°ƒç”¨ Apifox å¼€æ”¾ APIï¼Œè‡ªåŠ¨ç”Ÿæˆä¸€ç¯‡æ–°çš„æ¥å£æ–‡æ¡£æˆ–é”™è¯¯æ—¥å¿—ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "æ ‡é¢˜": {
                        "type": "string",
                        "description": "æ–‡æ¡£æ ‡é¢˜æ ¼å¼ï¼š[æ•…éšœè®°å½•] YYYY-MM-DD HH:mm:ss",
                    },
                    "å†…å®¹": {
                        "type": "string",
                        "description": "æ–‡æ¡£å†…å®¹",
                    }
                },
                "required": ["æ ‡é¢˜", "å†…å®¹"],
            },
        },
    },
]


def send_card(webhook: str, æŠ¥é”™æ—¶é—´: str = "", é”™è¯¯ä»£ç : str = "", å½“å‰å»¶è¿Ÿ: str = "") -> str:
    """å‘å¡ç‰‡åˆ°é£ä¹¦"""
    payload = {
        "msg_type": "interactive",
        "card": {
            "config": {"wide_screen_mode": True},
            "header": {
                "title": {"tag": "plain_text", "content": "ğŸš¨ APIæŠ¥é”™ ğŸš¨"},
                "template": "red"  # æ”¯æŒ red/green/blue/yellowâ€¦
            },
            "elements": [
                {
                    "tag": "div",
                    "text": {
                        "tag": "lark_md",
                        "content": f"æŠ¥é”™æ—¶é—´ï¼š{æŠ¥é”™æ—¶é—´}\né”™è¯¯ä»£ç ï¼š{é”™è¯¯ä»£ç }\nå½“å‰å»¶è¿Ÿï¼š{å½“å‰å»¶è¿Ÿ}"
                    }
                },
                {"tag": "hr"},
                {
                    "tag": "action",
                    "actions": [
                        {
                            "tag": "button",
                            "type": "primary",
                            "value": {"key": "click"},
                            "text": {"tag": "plain_text", "content": "æŸ¥çœ‹è¯¦æƒ…"}
                        }
                    ]
                }
            ]
        }
    }

    headers = {"Content-Type": "application/json; charset=utf-8"}
    resp = requests.post(webhook, data=json.dumps(payload), headers=headers)
    result = resp.json()
    # print(result)
    return result.get("msg")


# print(send_card(WEBHOOK_URL,"00:00:00","404","0ms"))
# èƒœç®—äº‘APIè°ƒç”¨


def LLM_invoke(message, tools=None):
    payload = json.dumps({
        "model": MODEL_ID,
        "stream": False,
        "messages": message,
        "tools": tools,
        "stream_options": {
            "include_usage": True
        }
    }) if tools else json.dumps({
        "model": MODEL_ID,
        "stream": False,
        "messages": message,
        "stream_options": {
            "include_usage": True
        }
    })
    start_time = datetime.datetime.now()

    CONNECTION.request("POST", "/api/v1/chat/completions", payload, HEADERS)
    res = CONNECTION.getresponse()
    obj = json.loads(res.read().decode('utf-8'))
    elapsed_time = datetime.datetime.now() - start_time
    log(obj)
    # print("-"*100,f"\nexecuted in {elapsed_time.total_seconds():.4f} seconds")
    # print("usage:",obj["usage"])
    try:
        content = obj["choices"][0]
    except:
        print("msg=", message)
        print("obj=", obj)
        content = "ï¼ˆæ¯”èµ›æ— å…³ï¼‰èƒœç®—äº‘APIé”™è¯¯"
    return content


# çŸ¥è¯†åº“


# TODO vector database
def query(question: str) -> str:
    q = question.lower()
    for k, v in KNOWLEDGE_BASE.items():
        if k.lower() in q:
            return v
    return "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"


# Agentæ„å»º
from typing import Dict, List, Optional, Any
from langgraph.graph import StateGraph, END
# from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel


class AgentState(BaseModel):
    case_id: str
    user_query: str
    api_status: str
    api_response_time: str
    monitor_log: List[Dict]

    # è¿è¡Œè¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸­é—´æ•°æ®
    user_intent: Optional[str] = None
    final_reply: Optional[str] = None
    action_apifox_id: Optional[str] = None
    action_log: Dict = {}


def monitor_node_state(func):
    """æ‰“å°AgentStateçš„è£…é¥°å™¨"""

    def inner(*args):
        # print(func.__name__,"entered:",args)
        log(*args)
        return func(*args)

    return inner


@monitor_node_state
def node_monitor(state: AgentState) -> AgentState:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦è§¦å‘æŠ¥è­¦æµç¨‹+åˆ¤æ–­ç”¨æˆ·æ„å›¾"""
    if state.api_status != "200 OK":
        sys_msg = (
            "ä½ æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚è¯·åŸºäºã€ç›‘æ§å†å²ã€‘ç»™å‡ºçœŸå®ã€è‡ªç„¶ã€ç®€æ´ã€ä¸“ä¸šåŒ–çš„å›ç­”ï¼Œè€Œä¸æ˜¯çç¼–ã€‚"
            "è§¦å‘æŠ¥è­¦æµç¨‹ã€‚é€šè¿‡ Webhook å‘æŒ‡å®šé£ä¹¦è´¦å·/ç¾¤å‘é€å¯Œæ–‡æœ¬å¡ç‰‡ã€‚"
            "å†…å®¹éœ€åŒ…å«ï¼šæŠ¥é”™æ—¶é—´ã€é”™è¯¯ä»£ç ã€å½“å‰å»¶è¿Ÿã€‚"
            "è°ƒç”¨ Apifox å¼€æ”¾ APIï¼Œè‡ªåŠ¨ç”Ÿæˆä¸€ç¯‡æ–°çš„æ¥å£æ–‡æ¡£æˆ–é”™è¯¯æ—¥å¿—ã€‚"
            "æ–‡æ¡£æ ‡é¢˜æ ¼å¼ï¼š[æ•…éšœè®°å½•] YYYY-MM-DD HH:mm:ssã€‚"
        )
        user_msg = f"ã€ç›‘æ§æ—¥å¿—ã€‘\n{state.api_status} å½“å‰å»¶è¿Ÿ:{state.api_response_time}{state.monitor_log}"
        messages = [
            {"role": "system", "content": sys_msg},
            {"role": "user", "content": user_msg},
        ]
        response = LLM_invoke(messages, tools=TOOLS)
        # è°ƒç”¨å·¥å…·
        for tc in response["message"]["tool_calls"]:
            func_name = tc["function"]["name"]
            args = json.loads(tc["function"]["arguments"])

            if func_name == "é£ä¹¦å‘Šè­¦":
                state.action_log["feishu_webhook"] = send_card(WEBHOOK_URL, **args)  # å‘é€å¯Œæ–‡æœ¬å¡ç‰‡

                print("é£ä¹¦å‘Šè­¦ args:", args, "\n", state.action_log["feishu_webhook"])
            elif func_name == "Apifox æ–‡æ¡£åŒæ­¥":
                print("ï¼ˆæ¨¡æ‹Ÿï¼‰Apifox æ–‡æ¡£åŒæ­¥ args:", args)
                state.action_log["apifox_doc_id"] = args["æ ‡é¢˜"]

    # å¦‚æœuser_queryæœ‰å†…å®¹åˆ™è®©å¤§æ¨¡å‹ç¡®å®šç”¨æˆ·æ„å›¾
    if state.user_query:
        """è®©å¤§æ¨¡å‹å†³å®šå›å¤å†…å®¹ï¼ˆç³»ç»Ÿæ­£å¸¸åˆ†æ”¯ï¼‰"""
        sys_msg = (
            "ä½ æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜åˆ¤æ–­ç”¨æˆ·çš„æ„å›¾ï¼Œå¦‚æœç”¨æˆ·é—®çš„æ˜¯ä¸šåŠ¡é—®é¢˜ï¼Œè¾“å‡º\"ä¸šåŠ¡\"ï¼Œå¦‚æœç”¨æˆ·é—®çš„æ˜¯ç³»ç»ŸçŠ¶æ€é—®é¢˜ï¼Œè¾“å‡º\"çŠ¶æ€\"ã€‚"
        )
        user_msg = f"{state.user_query}"
        print("user:  ", user_msg)
        messages = [
            {"role": "system", "content": sys_msg},
            {"role": "user", "content": user_msg},
        ]
        judgement = LLM_invoke(messages)["message"]["content"]
        # print("judgement:", judgement)

        if judgement == "ä¸šåŠ¡":
            state.user_intent = "ä¸šåŠ¡"
        elif judgement == "çŠ¶æ€":
            state.user_intent = "çŠ¶æ€"
        else:
            state.user_intent = judgement
    # å¦åˆ™å°±æ˜¯ä¾‹è¡Œç›‘æ§
    else:
        state.user_intent = "ç›‘æ§"
    return state


@monitor_node_state
def node_knowledge(state: AgentState) -> AgentState:
    """å¤§æ¨¡å‹å›å¤ä¸šåŠ¡é—®é¢˜"""
    sys_msg = (
        "ä½ æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚è¯·æ ¹æ®ã€ç”¨æˆ·é—®é¢˜ã€‘å’Œã€çŸ¥è¯†åº“ç‰‡æ®µã€‘ç”Ÿæˆä¸€æ®µè‡ªç„¶ã€ç®€æ´ã€å£è¯­åŒ–çš„å›å¤ã€‚"
        "å¦‚æœçŸ¥è¯†åº“ç‰‡æ®µä¸ºç©ºï¼Œå¯å§”å©‰è¡¨ç¤ºæš‚æœªæ‰¾åˆ°ä¿¡æ¯ã€‚"
    )
    user_msg = f"ã€ç”¨æˆ·é—®é¢˜ã€‘{state.user_query}\nã€çŸ¥è¯†åº“ç‰‡æ®µã€‘{query(state.user_query)}"
    messages = [
        {"role": "system", "content": sys_msg},
        {"role": "user", "content": user_msg},
    ]
    state.final_reply = LLM_invoke(messages)["message"]["content"]
    return state


@monitor_node_state
def node_server(state: AgentState) -> AgentState:
    """å¤§æ¨¡å‹å›å¤ç³»ç»Ÿç³»ç»ŸçŠ¶æ€é—®é¢˜"""
    sys_msg = (
        "ä½ æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ã€‚è¯·åŸºäºã€ç”¨æˆ·é—®é¢˜ã€‘å’Œã€ç›‘æ§å†å²ã€‘ç»™å‡ºçœŸå®ã€è‡ªç„¶ã€ç®€æ´ã€ä¸“ä¸šåŒ–çš„å›ç­”ï¼Œè€Œä¸æ˜¯çç¼–ã€‚"
        "å¦‚æœçŸ¥è¯†åº“ç‰‡æ®µä¸ºç©ºï¼Œå¯å§”å©‰è¡¨ç¤ºæš‚æœªæ‰¾åˆ°ä¿¡æ¯ã€‚"
        "ä½ ä¸éœ€è¦è°ƒç”¨å·¥å…·ã€‚"
    )
    user_msg = f"ã€ç”¨æˆ·é—®é¢˜ã€‘{state.user_query}\nã€ç›‘æ§æ—¥å¿—ã€‘{state.api_status}{state.api_response_time}{state.monitor_log}"
    messages = [
        {"role": "system", "content": sys_msg},
        {"role": "user", "content": user_msg},
    ]
    response = LLM_invoke(messages)
    state.final_reply = response["message"]["content"]
    return state


def build_graph():
    workflow = StateGraph(AgentState)

    workflow.add_node("monitor", node_monitor)
    workflow.set_entry_point("monitor")

    workflow.add_node("knowledge", node_knowledge)
    workflow.add_node("server", node_server)

    # æ¡ä»¶è¾¹ï¼šretrieve ä¹‹åæ ¹æ®ç³»ç»ŸçŠ¶æ€åˆ†æ”¯
    # @print_state_info
    def _router(state: AgentState):
        if state.user_intent == "ç›‘æ§":
            return "ç›‘æ§"
        elif state.user_intent == "çŠ¶æ€":
            return "çŠ¶æ€"
        elif state.user_intent == "ä¸šåŠ¡":
            return "ä¸šåŠ¡"
        else:
            return "çŠ¶æ€"  # æ¨¡å‹æœªæŒ‰è¦æ±‚è¾“å‡ºæ—¶é»˜è®¤çŠ¶æ€æŸ¥è¯¢

    workflow.add_conditional_edges(
        "monitor",
        _router,
        {"çŠ¶æ€": "server", "ä¸šåŠ¡": "knowledge", "ç›‘æ§": END},
    )

    workflow.add_edge("server", END)
    workflow.add_edge("knowledge", END)

    # memory = MemorySaver()
    graph = workflow.compile(checkpointer=False)  # memory) æš‚ä¸ä½¿ç”¨æ£€æŸ¥ç‚¹

    # ç”Ÿæˆæ¨¡å‹ç»“æ„æµç¨‹å›¾
    mmd_graph = graph.get_graph().draw_mermaid().replace("classDef", "%% classDef")
    with open("graph.mmd", "w", encoding='utf-8') as f:
        #å¯èƒ½å‡ºç°æ±‰å­—ç¼–ç é—®é¢˜
        try:
            f.write(mmd_graph)
        except UnicodeDecodeError as e:
            print(e)
        except Exception as e:
            print(e)
        # assert False, "breakpoint"
    return graph


class SmartAgent:
    def __init__(self):
        self.graph = build_graph()

    def process(self, case: Dict[str, Any]) -> Dict[str, Any]:
        state = AgentState(**case)
        print("=" * 100, "\ncase:", case,"\n","-" * 100)
        # thread = {"configurable": {"thread_id": case["case_id"]}}
        # print("-"*100,"\nstate.model_dump():",state.model_dump())
        final_state = self.graph.invoke(state.model_dump())  # , config=thread)
        print("agent:", final_state["final_reply"])
        # ç»„è£…æˆæ—§æ ¼å¼
        return {
            "case_id": final_state["case_id"],
            "reply": final_state["final_reply"],
            "action_triggered": final_state["action_log"]
        }


# è¯»å–è¾“å…¥æ•°æ®
try:
    with open("../inputs.json", "r", encoding="utf-8") as f:
        inputs = json.load(f)
    print(f"âœ… æˆåŠŸè¯»å– {len(inputs)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
except FileNotFoundError:
    print("âŒ æœªæ‰¾åˆ° inputs.json!")

# è¿è¡ŒAgent
print("=" * 100)
print("æ™ºèƒ½å®¢æœç›‘æ§ Agentå¯åŠ¨")
print("=" * 100)

agent = SmartAgent()
# results = agent.process(inputs[0])
results = [agent.process(case) for case in inputs]
# æ–‡ä»¶è¾“å‡º
os.makedirs("outputs", exist_ok=True)
with open("../outputs/results.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print("âœ… å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° outputs/results.json")
